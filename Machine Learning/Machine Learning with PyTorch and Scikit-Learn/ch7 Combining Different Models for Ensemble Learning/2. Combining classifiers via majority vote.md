Our goal is to build a stronger meta-classifier that balances out the individual classifiers’ weaknesses on a particular dataset. In more precise mathematical terms, we can write the weighted majority vote as follows:
<!--⚠️Imgur upload failed, check dev console-->
![[Pasted image 20250616100303.png]]
<!--⚠️Imgur upload failed, check dev console-->
![[Pasted image 20250616100405.png]]
<!--⚠️Imgur upload failed, check dev console-->
![[Pasted image 20250616100517.png]]
via the predict_proba method, he modified version of the majority vote for
predicting class labels from probabilities can be written as follows:
<!--⚠️Imgur upload failed, check dev console-->
![[Pasted image 20250616100917.png]]
Here, pij is the predicted probability of the jth classifier for class label i.
<!--⚠️Imgur upload failed, check dev console-->
![[Pasted image 20250616101250.png]]

let’s now implement MajorityVoteClassifier in Python:
```
from sklearn.base import BaseEstimator
from sklearn.base import ClassifierMixin
from sklearn.preprocessing import LabelEncoder
from sklearn.base import clone
from sklearn.pipeline import _name_estimators
import operator
class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, classifiers, vote='classlabel', weights=None):
        self.classifiers = classifiers
        self.named_classifiers = {
            key: value for key,
            value in _name_estimators(classifiers)
        }
        self.vote = vote
        self.weights = weights
    def fit(self, X, y):
        if self.vote not in ('probability', 'classlabel'):
            raise ValueError(f"vote must be 'probability' "
                             f"or 'classlabel'"
                             f"; got(vote={self.vote})")
        if self.weights and len(self.weights) != len(self.classifiers):
            raise ValueError(f'Number of classifiers and'f' weights must be equal'f'; got {len(self.weights)} weights,'f' {len(self.classifiers)} classifiers')
        # Use LabelEncoder to ensure class labels start
        # with 0, which is important for np.argmax
        # call in self.predict
        self.lablenc_ = LabelEncoder()
        self.lablenc_.fit(y)
        self.classes_ = self.lablenc_.classes_
        self.classifiers_ = []
        for clf in self.classifiers:
            fitted_clf = clone(clf).fit(X,
                                        self.lablenc_.transform(y))
            self.classifiers_.append(fitted_clf)
        return self
```
