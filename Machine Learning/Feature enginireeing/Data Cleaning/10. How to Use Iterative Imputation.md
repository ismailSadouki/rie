
A sophisticated approach involves defining a model to predict each
missing feature as a function of all other features and to repeat this process of estimating feature values multiple times. The repetition allows the refined estimated values for other features to be used as input in subsequent iterations of predicting missing values. This is generally referred to as iterative imputation.


Iterative imputation refers to a process where each feature is modeled as a function of the other features, e.g. a regression problem where missing values are predicted. Each feature is imputed sequentially, one after the other, allowing prior imputed values to be used as part of a model in predicting subsequent features.
It is iterative because this process is repeated multiple times, allowing ever improved estimates of missing values to be calculated as missing values across all features are estimated. This approach may be generally referred to as fully conditional specification (FCS) or multivariate imputation by chained equations (MICE).

```
This methodology is attractive if the multivariate distribution is a reasonable description of the data. FCS specifies the multivariate imputation model on a variable-by-variable basis by a set of conditional densities, one for each incomplete variable. Starting from an initial imputation, FCS draws imputations by iterating over the conditional densities. A low number of iterations (say 10-20) is often
sufficient.
— mice: Multivariate Imputation by Chained Equations in R, 2009.
```
Different regression algorithms can be used to estimate the missing values for each feature, although linear methods are often used for simplicity. The number of iterations of the procedure is often kept small, such as 10. Finally, the order that features are processed sequentially can be considered, such as from the feature with the least missing values to the feature with the most missing values.


report the number of rows with missing values for
the column
```
# summarize the number of rows with missing values for each column
for i in range(dataframe.shape[1]):
	# count number of rows with missing values
	n_miss = dataframe[[i]].isnull().sum()
	perc = n_miss / dataframe.shape[0] * 100
	print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))
```

### 10.4.1 IterativeImputer Data Transform
It is a data transform that is first configured based on the method used to estimate the missing values. By default, a BayesianRidge model is employed that uses a function of all other input features. Features are filled in ascending order, from those with the fewest missing values to those with the most.
```
# define imputer
imputer = IterativeImputer(estimator=BayesianRidge(), n_nearest_features=None,imputation_order='ascending')
# fit on the dataset
imputer.fit(X)
```

### 10.4.3 IterativeImputer and Different Imputation Order
By default, imputation is performed in ascending order from the feature with the least missing values to the feature with the most. This makes sense as we want to have more complete data when it comes time to estimating missing values for columns where the majority of values are missing. Nevertheless, we can experiment with different imputation order strategies, such as descending, right-to-left (Arabic), left-to-right (Roman), and random.

At the end of the run, u could use a box and whisker plot for each set of results, allowing the distribution of results to be compared.



### 10.4.4 IterativeImputer and Different Number of Iterations
By default, the IterativeImputer will repeat the number of iterations 10 times. It is possible that a large number of iterations may begin to bias or skew the estimate and that few iterations may be preferred. The number of iterations of the procedure can be specified via the max_iter argument. It may be interesting to evaluate different numbers of iterations.

# 10.5 Further Reading
mice: Multivariate Imputation by Chained Equations in R, 2009.
https://www.jstatsoft.org/article/view/v045i03
 A Method of Estimation of Missing Values in Multivariate Data Suitable for use with an
Electronic Computer, 1960.
https://www.jstor.org/stable/2984099?seq=1