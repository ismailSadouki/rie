
### <mark>New Research keywords</mark>
#statistical-and-probabilistic-algorithms
#Monte-Carlo-algorithm
#Greedy-algorithms #Continuous-Learning-algorithms
#Bayesian-Probabilism
#Single-Shot-Learning
#Meta-learning



### What is computation?
It is the act of running an algorithmic recipe on a machine. A computation process takes input data and outputs some form of result;

## Probabilistic Turing Machine (PTM)
A **Probabilistic Turing Machine (PTM)** is a Turing machine that incorporates **randomness** in its state transitions, allowing multiple possible computational paths. It can make decisions based on **probability**, often using a coin flip mechanism.
PTMs help in designing **randomized algorithms** that can efficiently tackle problems where deterministic approaches struggle.
Uses **randomized state transitions** instead of deterministic rules.

### objective-less Algorithm
is an exciting alternative. The algorithm is placed in an environment and then left to discover. Progress occurs when a new experience is discovered and recorded.
### Novelty Search
Novelty Search is objective-less algorithm, an **alternative optimization method** that rewards exploration rather than direct goal achievement. It is useful for problems where **creativity, diversity, and open-ended exploration** are more important than pure optimization.


### Fractional Factorial Design
Fractional Factorial Design is a statistical method used to study multiple factors with fewer experiments than a full factorial design. It relies on the sparsity-of-effects principle, which assumes that only a few factors significantly impact the outcome, while most interactions are negligible. This allows researchers to extract key insights efficiently, reducing experimental costs and effort.

By selecting a fraction of possible factor combinations, this method helps identify the most important features in data with minimal work, making it widely used in engineering, manufacturing, and data-driven decision-making.

### **What is Continuous Learning?**

Continuous learning refers to an algorithmâ€™s ability to **adapt and improve over time** as it interacts with its environment. This concept is **closely related to evolutionary algorithms**, where an algorithm is placed in an environment with resources and is allowed to **learn, optimize, and evolve**.


### **Bayesian Probabilism**

Bayesian probabilism is a **probabilistic reasoning approach** that updates beliefs based on new evidence using **Bayesian inference**. It represents **uncertainty with probabilities** and refines knowledge as more data becomes available. This method is especially useful in **robotics, AI, and decision-making under uncertainty**.

A key application is **Simultaneous Localization and Mapping (SLAM)**, where a robot or self-driving car **estimates its location** and **maps its environment** using **sensor data** while continuously updating its belief. Bayesian probabilism is effective in **handling incomplete or noisy data**, making it valuable for **navigation, AI, finance, and healthcare**.


### Neuromorphic Computing
**Neuromorphic computing** is a field of computer engineering that designs hardware and algorithms inspired by the **structure and function of the human brain**. Instead of relying on traditional von Neumann architectures, it uses **spiking neural networks (SNNs)** and specialized hardware to mimic biological neural processes.

### **Single-Shot Learning Algorithms**

**Single-shot learning (SSL)** refers to the ability of an algorithm to **learn from just one or very few examples**, unlike traditional machine learning models that require large datasets. This trend aligns with efforts to **reduce the data required** to train next-generation AI models, making them more efficient and adaptable.











