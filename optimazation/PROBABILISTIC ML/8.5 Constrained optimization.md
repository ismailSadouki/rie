We initially assume that we have just one equality constraint, h(θ) = 0.
First note that for any point on the constraint surface, ∇h(θ) will be orthogonal to the constraint surface.
To see why, consider another point nearby, $θ + \epsilon$, that also lies on the surface. If we make a first-order Taylor expansion around θ we have
![](https://i.imgur.com/uRyy78S.png)
We seek a point $θ^ ∗$ on the constraint surface such that L(θ) is minimized
Since both ∇h(θ) and ∇L(θ) are orthogonal to the constraint surface at $θ^ ∗$ , they must be parallel (or anti-parallel) to each other. Hence there must exist a constant $λ^∗$ ∈ R such that
![](https://i.imgur.com/RMEupsF.png)
(We cannot just equate the gradient vectors, since they may have different magnitudes.)
Lagrange multiplier can be positive, negative, or zero. This latter case occurs
when $∇L(θ ^∗ ) = 0$.
We can convert Equation (8.89) into an objective, known as the Lagrangian, that we should find a stationary point of the following:
![](https://i.imgur.com/Gr2V3rl.png)
This is called a critical point, and satisfies the original constraint h(θ) = 0 and Equation (8.89).
If we have m > 1 constraints, we can form a new constraint function by addition, as follows:
![](https://i.imgur.com/5nVzKEs.png)

We now have D+m equations in D+m unknowns and we can use standard unconstrained optimization methods to find a stationary point. We give some examples below.

## 8.5.1.1 Example: 2d Quadratic objective with one linear equality constraint
![](https://i.imgur.com/o4Za48p.png)
# 8.5.2 The KKT conditions
