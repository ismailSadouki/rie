Optimization algorithms that only use the gradient are called first-order methods. They have the advantage that the gradient is cheap to compute and to store, but they do not model the curvature of the space, and hence they can be slow to converge
Second-order optimization methods incorporate curvature in various ways (e.g., via the Hessian)
## 8.3.1 Newton’s method
![](https://i.imgur.com/zSLqr8R.png)
is assumed to be positive-definite to ensure the update is well-defined
The intuition for why this is faster than gradient descent is that the
matrix inverse H−1 “undoes” any skew in the local curvature, converting a topology

![](https://i.imgur.com/cgujOXV.png)
This algorithm can be derived as follows. Consider making a second-order Taylor series approximation of L(θ) around θt :
![](https://i.imgur.com/qPMF4xo.png)
![](https://i.imgur.com/CteIGxa.png)
![](https://i.imgur.com/xFcQa4F.png)
![](https://i.imgur.com/jxPVdnn.png)
![](https://i.imgur.com/xQJcZuZ.png)


# 8.3.2 BFGS and other quasi-Newton methods
Quasi-Newton methods, sometimes called variable metric methods, iteratively build up an approximation to the Hessian using information gleaned from the gradient vector at each step.
The most common method is called BFGS which updates the approximation to the Hessian $B_t ≈ H_t$ as follows:
![](https://i.imgur.com/ngrETXU.png)
This is a rank-two update to the matrix. If $B_0$ is positive-definite, and the step size η is chosen via line search satisfying both the Armijo condition in Equation (8.27) and the following curvature condition![](https://i.imgur.com/4NmFlHr.png)
then $B_{t+1}$ will remain positive definite.
The constant c2 is chosen within (c, 1) where c is the tunable parameter in Equation (8.27). The two step size conditions are together known as the Wolfe
conditions.
We typically start with a diagonal approximation, B0 = I. Thus BFGS can be thought of as a “diagonal plus low-rank” approximation to the Hessian.
![](https://i.imgur.com/J9wNjqo.png)
![](https://i.imgur.com/oZAtHbD.png)

# 8.3.3 Trust region methods
If the objective function is nonconvex, then the Hessian $H_t$ may not be positive definite, so $d_t = −H^{−1}_ t g_t$ may not be a descent direction.
This is illustrated in 1d in Figure 8.14(b), which shows that Newton’s method can end up in a local maximum rather than a local minimum.

In general, any time the quadratic approximation made by Newton’s method becomes invalid, we are in trouble. However, there is usually a local region around the current iterate where we can safely approximate the objective by a quadratic. Let us call this region $R^t$ , and let us call $M (δ)$ the model (or approximation) to the objective, where $δ = θ − θ_t$ . Then at each step we can solve
![](https://i.imgur.com/VNf7uFb.png)
This is called **trust-region optimization**.
(This can be seen as the “opposite” of line search, in the sense that we pick a distance we want to travel, determined by Rt , and then solve for the optimal direction, rather than picking the direction and then solving for the optimal distance.)
We usually assume that $M_t (δ)$ is a quadratic approximation:
![](https://i.imgur.com/aCSpmcN.png)
![](https://i.imgur.com/BCytZpJ.png)
![](https://i.imgur.com/DMTqAcD.png)
![](https://i.imgur.com/MK6f4qH.png)
